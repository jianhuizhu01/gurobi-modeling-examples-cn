{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_27Lz77SEy5"
   },
   "source": [
    "# 最优子集选择：L0回归\n",
    "\n",
    "## 目标与准备工作\n",
    "\n",
    "在本示例中，您将学习如何使用数学规划来执行具有特征选择的线性回归。我们将向您展示如何在Gurobi Python API中构建这个线性回归问题的混合整数二次规划(MIQP)模型，并生成最优解。\n",
    "\n",
    "这个建模示例属于中级水平，我们假设您了解Python并熟悉Gurobi Python API。此外，您还应该具备构建数学优化模型的相关知识。\n",
    "\n",
    "**下载代码库** <br />\n",
    "您可以通过点击[此处](https://github.com/Gurobi/modeling-examples/archive/master.zip)下载包含此示例和其他示例的代码库。\n",
    "\n",
    "---\n",
    "## 动机\n",
    "\n",
    "线性回归发明于19世纪初，时至今日200多年后，它仍然在实际应用中被广泛用于描述和预测目的：\n",
    "\n",
    "- 在计量经济学中，通过对销售收入关于价格以及其他可能的特征(如人口统计、竞争对手和零售信息)进行回归分析，可以用来估计特定产品的价格弹性。\n",
    "- 在医疗卫生领域，可以用来根据患者信息、分诊评估、医学检验结果和到达时间等预测患者在医院急诊室的停留时间(即住院时长)。\n",
    "- 在社会科学中，它可以帮助预测学生未来的学业表现，从而采取主动措施改善其学习成果。\n",
    "\n",
    "一般来说，线性回归用于建模连续变量与其他解释变量(可以是连续的或分类的)之间的关系。在应用这种技术时，找到能够最大化其性能的特征子集通常很重要。\n",
    "\n",
    "---\n",
    "## 问题描述\n",
    "\n",
    "线性回归是一种用于预测定量响应的监督学习算法。它假设特征向量 $x_i \\in \\mathbb{R}^d$ 和响应 $y_i \\in \\mathbb{R}$ 之间存在线性关系。从数学角度来说，对于样本 $i$，我们有 $y_i = \\beta^T x_i + \\epsilon_i$，其中 $\\beta \\in \\mathbb{R}^d$ 是特征权重向量(包括截距项)，$\\epsilon_i$ 是均值为0且方差恒定的正态分布随机变量，代表误差项。我们可以从训练数据集 $\\{X \\in \\mathbb{M}^{nxd},y \\in \\mathbb{R}^n\\}$ 中学习权重，方法是最小化残差平方和(RSS): $e^Te =(y-X\\beta)^T (y-X\\beta)=\\beta^T X^T X\\beta- 2y^TX\\beta+y^T y$。普通最小二乘法(OLS)通过对这个二次凸函数求导并找到驻点来实现：$\\beta_{OLS}=(X^T X)^{-1} X^T y$。\n",
    "\n",
    "实际上，某些特征与响应变量并没有关联。包含这些特征只会给模型增加不必要的复杂性，并增加权重估计的方差。然而，找到表现最好的模型并非易事，因为候选模型的数量是指数级的，需要测试 $\\sum_{s=1}^{d-1}{{d-1} \\choose s}$ 个模型。由于OLS很少得到恰好为零的估计值(从而丢弃相关的特征)，我们需要借助特征选择方法。常用方法包括：\n",
    "\n",
    "- 子集选择，如逐步选择。\n",
    "- 降维，如主成分回归。\n",
    "- 收缩，如Lasso。\n",
    "\n",
    "Lasso无疑是过去十年最受欢迎的方法。基本上，它拟合包含所有 $d$ 个预测变量的模型，同时加入基于 $\\beta$ 的L1范数的预算约束，不考虑截距项。实际上，这种方法最小化RSS，同时受限于 $\\sum_{l=1}^{d-1}\\mathopen|\\beta_l\\mathclose| \\leq s$，其中 $s$ 是通常通过交叉验证调整的超参数，代表预算。这个约束具有收缩所有权重估计的效果，当 $s$ 足够小时，允许其中一些恰好为零。最后值得注意的是，Lasso的无约束版本更常用。这个版本解决了一个无约束优化问题，最小化 $RSS + \\lambda \\sum_{l=1}^{d-1}\\mathopen|\\beta_l\\mathclose|$，其中 $\\lambda \\in \\mathbb{R}^+$ 是给定的修改后的拉格朗日乘子。\n",
    "\n",
    "现在介绍一个类似的公式，这里使用L0-范数代替(尽管它并不是真正的范数)。我们现在寻求最小化RSS，受限于 $\\sum_{l=1}^{d-1}I(\\beta_l \\neq 0) \\leq s$，其中 $I(\\beta_l \\neq 0)$ 是一个指示函数，当 $\\beta_j \\neq 0$ 时取值为1，否则为0。在这种设置下，$s$ 代表模型中要考虑的特征数量。这个优化问题可以转化为混合整数二次规划(MIQP)。传统上，特征选择问题没有用这种方式处理，因为统计学界普遍认为大规模问题难以解决。但考虑到目前可用的计算能力和现代优化求解器(如Gurobi)的性能，这种情况已不再存在。\n",
    "\n",
    "---\n",
    "## 解决方案方法\n",
    "\n",
    "数学规划是一种声明式方法，其中建模者制定一个能够捕捉复杂决策问题关键方面的数学优化模型。Gurobi优化器使用最先进的数学和计算机科学来求解这些模型。\n",
    "\n",
    "数学优化模型有五个组成部分，即：\n",
    "\n",
    "- 集合和索引。\n",
    "- 参数。\n",
    "- 决策变量。\n",
    "- 目标函数。\n",
    "- 约束条件。\n",
    "\n",
    "我们现在提出一个MIQP公式，用于找到线性回归问题的权重估计，其中恰好 $s$ 个权重可以为非零：\n",
    "\n",
    "### 集合和索引\n",
    "\n",
    "$l \\in L$: 特征集合，不包括截距项。\n",
    "\n",
    "### 参数\n",
    "\n",
    "$s \\in \\mathbb{N}$: 模型中要包含的特征数量，不包括截距项。\n",
    "\n",
    "### 决策变量\n",
    "\n",
    "$\\beta \\in \\mathbb{R}^d$: 特征权重向量，其中第j个元素表示响应变量随特征 $j$ 每单位变化的变化量。请注意最后一个分量对应截距项。\n",
    "\n",
    "$\\text{norm}_0 \\in \\mathbb{R}$: 向量 $\\beta$ 的非零元素数量，不包括截距项。\n",
    "\n",
    "### 目标函数\n",
    "\n",
    "- **训练误差**: 最小化残差平方和(RSS)：\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Min} \\quad Z = \\beta^T X^T X\\beta- 2y^TX\\beta+y^T y\n",
    "\\tag{0}\n",
    "\\end{equation}\n",
    "\n",
    "### 约束条件\n",
    "\n",
    "- **L0范数**: 计算非零权重特征的数量：\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{norm}_0 = \\sum_{l \\in L}I(\\beta_l \\neq 0)\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "- **预算约束**: 恰好 $s$ 个特征权重可以为非零：\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{norm}_0 = s\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "这个模型通过约束2隐式地同时考虑了所有 ${{d-1} \\choose s}$ 个特征子集。然而，我们还需要找到使回归在未见样本上性能最大化的 $s$ 值。请注意，随着考虑更多特征（这相当于放宽MIQP），训练RSS会单调下降，所以不建议将其用作性能指标。相反，我们将通过交叉验证来估计均方误差(MSE)。这个指标定义为 $\\text{MSE}=\\frac{1}{n}\\sum_{i=1}^{n}{(y_i-\\hat{y}_i)^2}$，其中 $y_i$ 和 $\\hat{y}_i$ 分别是第i个观测的观察值和预测值。然后，我们将使用网格搜索来微调 $s$，因为可能的值集合相当小。\n",
    "\n",
    "---\n",
    "## Python实现\n",
    "\n",
    "在下面的实现中，我们使用四个主要库：\n",
    "\n",
    "- **Numpy** 用于科学计算。\n",
    "- **Scikit learn** 用于机器学习算法。\n",
    "- **Gurobi** 用于数学优化。\n",
    "- **Matplotlib** 用于可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7BAwEkmSEy_"
   },
   "outputs": [],
   "source": [
    "# %pip install gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBbsv7ywSEzA"
   },
   "outputs": [],
   "source": [
    "# 导入所有必需的库\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTc0wIyMSEzB"
   },
   "outputs": [],
   "source": [
    "# 创建和部署优化模型\n",
    "\n",
    "# 注意：此函数假设设计矩阵特征不包含截距项列\n",
    "def miqp(features, response, non_zero, verbose=False):\n",
    "    \"\"\"\n",
    "    部署和优化L0回归的MIQP公式。\n",
    "    \"\"\"\n",
    "    assert isinstance(non_zero, (int, np.integer))\n",
    "    # 创建Gurobi环境和模型对象\n",
    "    with gp.Env() as env, gp.Model(\"\", env=env) as regressor:\n",
    "        samples, dim = features.shape\n",
    "        assert samples == response.shape[0]\n",
    "        assert non_zero <= dim\n",
    "\n",
    "        # 添加一列1到特征矩阵以考虑y截距\n",
    "        X = np.concatenate([features, np.ones((samples, 1))], axis=1)  \n",
    "\n",
    "        # 决策变量\n",
    "        norm_0 = regressor.addVar(lb=non_zero, ub=non_zero, name=\"norm\")\n",
    "        beta = regressor.addMVar((dim + 1,), lb=-GRB.INFINITY, name=\"beta\") # 权重\n",
    "        intercept = beta[dim] # 最后的决策变量捕获y截距\n",
    "\n",
    "        regressor.setObjective(beta.T @ X.T @ X @ beta\n",
    "                               - 2*response.T @ X @ beta\n",
    "                               + np.dot(response, response), GRB.MINIMIZE)\n",
    "\n",
    "        # 基于L0范数的预算约束\n",
    "        regressor.addGenConstrNorm(norm_0, beta[:-1], which=0, name=\"budget\")\n",
    "\n",
    "        if not verbose:\n",
    "            regressor.params.OutputFlag = 0\n",
    "        regressor.params.timelimit = 60\n",
    "        regressor.params.mipgap = 0.001\n",
    "        regressor.optimize()\n",
    "\n",
    "        coeff = np.array([beta[i].X for i in range(dim)])\n",
    "        return intercept.X, coeff        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6dLWd6KSEzB"
   },
   "outputs": [],
   "source": [
    "# 定义执行超参数调优所需的交叉验证函数\n",
    "\n",
    "def split_folds(features, response, train_mask):\n",
    "    \"\"\"\n",
    "    根据train_mask将折叠分配给训练或测试分区。\n",
    "    \"\"\"\n",
    "    xtrain = features[train_mask,:]\n",
    "    xtest = features[~train_mask,:]\n",
    "    ytrain = response[train_mask]\n",
    "    ytest = response[~train_mask]\n",
    "    return xtrain, xtest, ytrain, ytest\n",
    "\n",
    "def cross_validate(features, response, non_zero, folds, standardize, seed):\n",
    "    \"\"\"\n",
    "    对每个折叠训练L0回归并报告交叉验证MSE。\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    samples, dim = features.shape\n",
    "    assert samples == response.shape[0]\n",
    "    fold_size = int(np.ceil(samples / folds))\n",
    "    # 随机将每个样本分配给一个折叠\n",
    "    shuffled = np.random.choice(samples, samples, replace=False)\n",
    "    mse_cv = 0\n",
    "    # 每次排除一个折叠进行训练，以获得MSE的样本外估计\n",
    "    for fold in range(folds):\n",
    "        idx = shuffled[fold * fold_size : min((fold + 1) * fold_size, samples)]\n",
    "        train_mask = np.ones(samples, dtype=bool)\n",
    "        train_mask[idx] = False\n",
    "        xtrain, xtest, ytrain, ytest = split_folds(features, response, train_mask)\n",
    "        if standardize:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(xtrain)\n",
    "            xtrain = scaler.transform(xtrain)\n",
    "            xtest = scaler.transform(xtest)\n",
    "        intercept, beta = miqp(xtrain, ytrain, non_zero)\n",
    "        ypred = np.dot(xtest, beta) + intercept\n",
    "        mse_cv += mse(ytest, ypred) / folds\n",
    "    # 报告样本外MSE的平均值\n",
    "    return mse_cv\n",
    "\n",
    "def L0_regression(features, response, folds=5, standardize=False, seed=None):\n",
    "    \"\"\"\n",
    "    通过对预算执行网格搜索选择最佳L0回归模型。\n",
    "    \"\"\"\n",
    "    dim = features.shape[1]\n",
    "    best_mse = np.inf\n",
    "    best = 0\n",
    "    # 网格搜索找到要考虑的最佳特征数量\n",
    "    for i in range(1, dim + 1):\n",
    "        val = cross_validate(features, response, i, folds=folds,\n",
    "                             standardize=standardize, seed=seed)\n",
    "        if val < best_mse:\n",
    "            best_mse = val\n",
    "            best = i\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features)\n",
    "        features = scaler.transform(features)\n",
    "    intercept, beta = miqp(features, response, best)\n",
    "    return intercept, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JXo-uw1SEzC"
   },
   "source": [
    "---\n",
    "## 基准测试\n",
    "\n",
    "我们现在将上述方法的性能与使用所有特征的OLS回归和Lasso进行比较。这里使用波士顿数据集。该数据集测量了506套房屋的价格，以及提供其所在社区信息的13个特征。我们将使用原始的特征术语，感兴趣的读者可以访问[这个网站](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)了解更多信息。\n",
    "\n",
    "请注意，20%的样本被保留用于计算样本外MSE。结果指标显示在条形图中(如下所示)以方便比较模型之间的差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-rW7MFHSEzC"
   },
   "outputs": [],
   "source": [
    "# 定义如何显示条形图\n",
    "\n",
    "def plot_bar_chart(performance):\n",
    "    \"\"\"\n",
    "    在条形图中显示所有三个模型的性能。\n",
    "    \"\"\"\n",
    "    bar = plt.bar([1, 2, 3], performance, color=['r', 'g', 'y'],\n",
    "                  tick_label=['OLS', 'Lasso', 'L0-Regression'])\n",
    "    plt.title('Out-of-Sample MSE')\n",
    "    x1, x2, y1, y2 = plt.axis()\n",
    "    plt.axis((x1, x2, np.floor(np.min(performance)),\n",
    "              np.ceil(np.max(performance))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "GIw53gPCSEzD",
    "outputId": "7863c9e3-c861-4959-ba82-363101689433"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVyElEQVR4nO3de7SddX3n8fdHARlIBJUoiOGiCHS8ECR1qFS5FGnFKlYdkalcajXoWAUXl+WAWnSkrYwGqVNrcaEVTC0gKWgHRYZyWXSEMYmBAOFSKiCQQlCBUBW5fOeP5znDzuGcnH3IOQk/8n6ttRf7/J7f8+zv3pt89m//nstOVSFJas+z1ncBkqSnxgCXpEYZ4JLUKANckhplgEtSowxwSWqUAa5mJPlgknuSPJTkBeu7nvEkuS3J/uu7Dj3zGeAaSpIjkixL8osk/5bkr5NsOYn11yrUkmwMzAcOqKoZVfXTMfqckOTHfcDfmeTsp/p460OSfZJUkoWj2nfr2y8baDsoydIkDya5L8klSXbol52U5JH+dRi53b9On4zWCQNcE0pyDPBZ4DhgC2BPYHvg4iSbrKMyXgRsClw/To2HA4cC+1fVDGAucMk6qm0qrQReN+obxuHAzSN/JNkJOBM4hu792BH4EvD4wDpn9x90I7ctp71yrXMGuNYoyXOBTwEfrqrvVdUjVXUb8C66EH9P3+9vk3xmYL19ktzZ3z8L2A74Tj8aPH6cx3pOki8kubu/faFv2xm4qe92f5J/GmP13wQuqqpbAarq36rq9IFt/1GS5UlWJfnXJEeOrjXJ8UnuTbIiyduSHJjk5iQ/S3LCQP+Tknwrydn99pYk2W2c5/SsJB9LcmuSnyY5J8nz1/CS/xo4H3h3v/6z+9d6wUCfOcCPq+qS6qyqqvOq6o41bFfPQAa4JvI6upHval/rq+oh4LvAGyfaQFUdCtwBvKUfDZ4yTtcT6Ub3c4DdgNcCH6+qm4FX9H22rKr9xlj3KuCwJMclmdsH36B7gd8Hngv8EXBqktcMLN+6f57bAp8EvkL34bQH8Hrgk0leOtD/IOBc4PnA3wHn99M8o30EeBuwN/Bi4OfAX43z/EecCRzW3/9dum8ddw8sXwLsmuTUJPsmmTHB9vQMZYBrIlsB91XVo2MsW9Evnyp/CHy6qu6tqpV0I/9Dh1mxqr4BfJgu8C4H7k3ysYHl/6uqbu1HrJcD36cL5hGPACdX1SPA39M9r9P60e31dCH66oH+i6vqW33/+XThv+cYpR0JnFhVd1bVw8BJwDuTbLSG5/J/gOcn2YUuyM8ctfxfgX3oPmzOAe7rvwENBvm7ktw/cLt0vMdTuwxwTeQ+YKtxAmebfvmkJfnywA62kemJFwO3D3S7vW8bve52gzvoRtqrakFV7Q9sCXwA+HSS3+3XeVOSq/rpkPuBA1n9w+enVfVYf/+X/X/vGVj+S2AwIH8y8LiPA3eOVSvdNNM/jAQpsBx4jG5Of03OAv4E2Bf4h9ELq+qqqnpXVc2i+yB6A903mBHnVNWWA7d9J3g8NcgA10R+ADwMvH2wMcnmwJt4YkfhvwObDXTZetR2VrvsZVV9YGAH25/1zXfTBd6I7Vh96mBk3TsGd9CNsfyRqjoXuBZ4ZZLnAOcBnwNe1O/QuxDI+E97QrNH7iR5FvCSsWqlC/o3jQrTTavqrgm2fxbwX4ELq+oXa+pYVT+km+J65aSegZpngGuNquoBuqmMLyb5vSQb94ernUs36jyr77oUODDJ85NsDRw9alP3AC9lzb4JfDzJrCRb0c1Ff2OYOvvDHN+cZGa/4/BNdPPmVwObAM+hO8Lj0X7ZAcNsdw32SPL2/pvJ0XQfcleN0e/LwMlJtu/rnJXkoIk2XlU/pps3P3H0siS/neT9SV7Y/70r8NZxHl/PYAa4JtTvdDyBbgT7IF0o/gT4nX5eF7ogvwa4jW5+efQx2H9OF873Jzl2nIf6DLCIbuS8jG5n3WfG6Tvag32NdwD3A6cAH6yqK6tqFd3OxHPodiL+F+DbQ253PBcAB/fbOxR4ez8fPtpp/WN9P8kqupD9T8M8QF/7WKP6++kCe1k/hfQ9ummWwZ3DB486DvyhkcDXM0f8QQdpcpKcBOxUVe9Z37Vow+YIXJIaNWGAJ5md5NL+JIjrkxzVt++W5AfpTq/+Tn/ChyRpHZlwCiXJNsA2VbUkyUxgMd2JCV8Hjq2qy5O8F9ixqj4x3QVLkjoTjsCrakVVLenvr6I7jnVbYBfgir7bxcA7pqtISdKTjXs22Fj6w8d2pzsK4Tq6PeEXAP+ZgeNiR60zD5gHsPnmm++x6667rkW5krThWbx48X39SVurGfoolP403cvpTjde2B97+pfAC+gOk/pIVa3xGs1z586tRYsWTbp4SdqQJVlcVXNHtw81Au8v0nMesKCqFgJU1Y30J0P0V4t789SVK0mayDBHoQQ4A1heVfMH2kfOAnsW8HG6M84kSevIMMeB70V3ptl+6X4BZGmSA4FDktwM3Eh3DYivTWOdkqRRJpxCqaorGf+iP6dNbTmSpGF5JqYkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYN9av00lORT433S3xaW/Wntb5L0NOAI3BJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSoyYM8CSzk1yaZHmS65Mc1bfPSXJVkqVJFiV57fSXK0kaMcyZmI8Cx1TVkiQzgcVJLgZOAT5VVd9NcmD/9z7TV6okadCEAV5VK4AV/f1VSZYD2wIFPLfvtgVw93QVKUl6skldCyXJDsDuwNXA0cBFST5HNxXzuqkuTpI0vqF3YiaZAZwHHF1VDwIfBD5aVbOBjwJnjLPevH6OfNHKlSunomZJEkMGeJKN6cJ7QVUt7JsPB0bunwuMuROzqk6vqrlVNXfWrFlrW68kqTfMUSihG10vr6r5A4vuBvbu7+8H3DL15UmSxjPMHPhewKHAsiRL+7YTgPcDpyXZCPgVMG9aKpQkjWmYo1CuBMa7Mv8eU1uOJGlYnokpSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRm00UYcks4Ezga2Bx4HTq+q0JGcDu/TdtgTur6o501SnJGmUCQMceBQ4pqqWJJkJLE5ycVUdPNIhyeeBB6arSEnSk00Y4FW1AljR31+VZDmwLXADQJIA7wL2m8Y6JUmjTGoOPMkOwO7A1QPNrwfuqapbxllnXpJFSRatXLnyKRcqSVrd0AGeZAZwHnB0VT04sOgQ4JvjrVdVp1fV3KqaO2vWrKdeqSRpNcPMgZNkY7rwXlBVCwfaNwLeDuwxPeVJksYz4Qi8n+M+A1heVfNHLd4fuLGq7pyO4iRJ4xtmCmUv4FBgvyRL+9uB/bJ3s4bpE0nS9BnmKJQrgYyz7IipLkiSNBzPxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGjVhgCeZneTSJMuTXJ/kqIFlH05yU99+yvSWKkkatNEQfR4FjqmqJUlmAouTXAy8CDgIeHVVPZzkhdNZqCRpdRMGeFWtAFb091clWQ5sC7wf+Iuqerhfdu90FipJWt2k5sCT7ADsDlwN7Ay8PsnVSS5P8pvjrDMvyaIki1auXLnWBUuSOkMHeJIZwHnA0VX1IN3o/XnAnsBxwDlJMnq9qjq9quZW1dxZs2ZNUdmSpKECPMnGdOG9oKoW9s13Agur83+Bx4GtpqdMSdJowxyFEuAMYHlVzR9YdD6wX99nZ2AT4L5pqFGSNIZhjkLZCzgUWJZkad92AvBV4KtJrgN+DRxeVTUtVUqSnmSYo1CuBJ40t917z9SWI0kalmdiSlKjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNmjDAk8xOcmmS5UmuT3JU335SkruSLO1vB05/uZKkERsN0edR4JiqWpJkJrA4ycX9slOr6nPTV54kaTwTBnhVrQBW9PdXJVkObDvdhUmS1mxSc+BJdgB2B67um/4kybVJvprkeeOsMy/JoiSLVq5cuXbVSpL+v6EDPMkM4Dzg6Kp6EPhr4GXAHLoR+ufHWq+qTq+quVU1d9asWWtfsSQJGDLAk2xMF94LqmohQFXdU1WPVdXjwFeA105fmZKk0YY5CiXAGcDyqpo/0L7NQLc/AK6b+vIkSeMZ5iiUvYBDgWVJlvZtJwCHJJkDFHAbcOQ01CdJGscwR6FcCWSMRRdOfTmSpGF5JqYkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KgJAzzJ7CSXJlme5PokR41afmySSrLV9JUpSRptoyH6PAocU1VLkswEFie5uKpuSDIbeCNwx7RWKUl6kglH4FW1oqqW9PdXAcuBbfvFpwLHAzVtFUqSxjSpOfAkOwC7A1cneStwV1VdMx2FSZLWbJgpFACSzADOA46mm1Y5EThgiPXmAfMAtttuu6dUpCTpyYYagSfZmC68F1TVQuBlwI7ANUluA14CLEmy9eh1q+r0qppbVXNnzZo1dZVL0gZuwhF4kgBnAMuraj5AVS0DXjjQ5zZgblXdN011SpJGGWYEvhdwKLBfkqX97cBprkuSNIEJR+BVdSWQCfrsMFUFSZKG45mYktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1Kihf5V+vcsafxRIa6NqfVcg6SlwBC5JjTLAJalRBrgkNaqdOXBJ0+6yy9zXNF322Wfq9zU5ApekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNmjDAk8xOcmmS5UmuT3JU3/7fk1ybZGmS7yd58fSXK0kaMcwI/FHgmKr6DWBP4ENJ/iPwP6rq1VU1B/hH4JPTV6YkabQJA7yqVlTVkv7+KmA5sG1VPTjQbXPAKyJJ0jqUmsSV6JLsAFwBvLKqHkxyMnAY8ACwb1WtHGOdecC8/s9dgJvWtuhGbAXct76L0NB8v9qzIb1n21fVrNGNQwd4khnA5cDJVbVw1LL/BmxaVX86FZU+EyRZVFVz13cdGo7vV3t8z4Y8CiXJxsB5wILR4d37O+AdU1mYJGnNhjkKJcAZwPKqmj/Q/vKBbm8Fbpz68iRJ4xnmaoR7AYcCy5Is7dtOAP44yS7A48DtwAempcJ2nb6+C9Ck+H61Z4N/zya1E1OS9PThmZiS1CgDXJIaZYA/BUlekuSCJLckuTXJaUk2SbJPkn8co//vJ/lRkmuS3JDkyPVR94YiyUPru4ZnsrFe3yTPSXJ2kn9JcnV/zshY656U5K7+Ehw3JDlk2gseUpIXJ/nW+q5jMgzwSeqPylkInF9VLwd2BmYAJ4/Tf2O6nS1vqardgN2By9ZNtdI688fAz6tqJ+BU4LNr6HtqfwmOg4C/6f+NrJUka/3zkFV1d1W9c223sy4Z4JO3H/CrqvoaQFU9BnwUeC+w2Rj9Z9Id7fPTvv/DVbWhnI36tJHkLf3I8EdJ/neSF/Xte/ejwaX9splJtklyRd92XZLX930PSbKsb1tTQG2IDgK+3t//FvA7/WBnXFV1C/AL4HkASY5L8sP+InmfGumX5BNJbkxycZJvJjm2b78syZ8luRw4KskeSS5PsjjJRUm26ft9pB/tX5vk7/u2sd73HZJc1y/fNMnX+vf7R0n27duPSLIwyff6b+CnTOWLOFn+qPHkvQJYPNjQX1bgDmCn0Z2r6mdJvg3cnuQSugt/fbOqHl8n1WrElcCeVVVJ3gccDxwDHAt8qKr+uT/b+Fd0l364qKpOTvJsYLP+apufBfYAfg58P8nbqur89fFknoa2BX4CUFWPJnkAeAFrONU9yWuAW6rq3iQHAC8HXgsE+HaSN9AF/DvovrluBCxh9X9/W1bV3v0o/nLgoKpameRgum/F7wU+BuxYVQ8n2bJfb6z3fdCH+ufyqiS70r3fO/fL5vT1PAzclOSLVfWTybxYU8UAn7ww9oW7xmunqt6X5FXA/nT/47wROGK6CtSYXgKc3Y/KNgF+3Lf/MzA/yQJgYVXdmeSHwFf7UDi/qpYm2Q+4bOR6P33/NwDnr+sn8jQ11mh7vGOUP5rk/cBLgd/r2w7obz/q/55BF+gzgQuq6pcASb4zaltn9//dBXglcHE/8H82sKJfdi2wIMn5PPF+jfW+D273t4EvAlTVjUlup5suBbikqh7o67kB2J7+w2tdcwpl8q4HVrv+QpLnArOBW8dbqaqWVdWpdOHtZQfWvS8C/7OqXgUcCWwKUFV/AbwP+A/AVUl2raor6ML5LuCsJIcxdkDpCXfS/RsYmY/eAvhZkpNHpioG+p5aVbsABwNnJtmU7vX986qa0992qqozmPh1//f+vwGuH1j/VVV1QL/szcBf0X17Wpxko7He91HbXdPjPjxw/zHW40DYAJ+8S+i+Uh8G0H/F/jzwt3Rf91aTZEaSfQaa5tCduap1awu6QAY4fKQxycv6D9fPAouAXZNsD9xbVV+hu4zEa4Crgb2TbNW/54fQfWVX59s88bq+E/in6pw4EqqjV+ivq7SoX+8i4L39dAZJtk3yQrqpr7f0c9Iz6MJ4LDcBs5L8Vr/+xklekeRZwOyqupRu2mxLYMZY7/uo7V0B/GG/rZ2B7XgaXknVKZRJ6udQ/wD4UpJP0H0IXkh3eYHfott5c+fAKocAxyf5G+CXdCOGI9Zt1RuczUa9B/OBk4Bzk9wFXAXs2C87ut9B9RhwA/Bd4N3AcUkeAR4CDquqFemuunkp3ejswqq6YJ08m6efsV7fL9F9W/kX4Gd0r+EwPk13Mbzf6G8/6KcyHgLeU1U/7PchXUM38FlEd/nq1VTVr5O8E/jLJFvQZdsXgJuBb/RtoRv935/uF8VGv+/bDGzyS8CXkyyj+1GbI/o59CGf1rrhqfSSntaSzKiqh5JsRjcynjfyIzMbOkfgkp7uTk/3M46bAl83vJ/gCFySGuVOTElqlAEuSY0ywCWpUQa4JDXKAJekRv0/NoxmBBvxmB8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载数据并分割为训练集(80%)和测试集(20%)\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "y = raw_df.values[1::2, 2]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20,\n",
    "                                                random_state=10101)\n",
    "\n",
    "# 使用所有特征的OLS回归\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(Xtrain, ytrain)\n",
    "# 具有交叉验证惩罚项(lambda)的Lasso\n",
    "lasso = linear_model.LassoCV(cv=5)\n",
    "lasso.fit(Xtrain, ytrain)\n",
    "# 通过交叉验证选择最佳特征子集的L0回归\n",
    "intercept, beta = L0_regression(Xtrain, ytrain, seed=10101)\n",
    "\n",
    "# 使用条形图比较它们的性能\n",
    "performance = []\n",
    "performance.append(mse(ytest, lr.predict(Xtest)))\n",
    "performance.append(mse(ytest, lasso.predict(Xtest)))\n",
    "performance.append(mse(ytest, np.dot(Xtest, beta) + intercept))\n",
    "plot_bar_chart(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpothO6VSEzD"
   },
   "source": [
    "注意 Lasso 表现不佳，这是因为我们没有将特征标准化为相同的单位（均值为零，方差为一）。与 OLS 和 L0 回归不同，Lasso 不具有尺度不变性，因为其预算约束基于 L1 范数。请记住，$\\beta_l$ 被解释为特征 $l$ 每单位变化对响应变量的影响。由于 L1 范数取绝对值之和，$\\beta_l$ 消耗多少预算取决于与之相关的特征的测量单位。\n",
    "\n",
    "这种预处理包含三个步骤，即：\n",
    "\n",
    "对于每个特征 $x_l$：\n",
    "1. 计算其样本均值 $\\mu_l$ 和样本标准差 $\\sigma_l$。\n",
    "2. 通过从 $x_l$ 中减去 $\\mu_l$ 进行中心化。\n",
    "3. 通过将得到的差除以 $\\sigma_l$ 进行缩放。\n",
    "\n",
    "为了报告应用标准化后 Lasso 的性能，我们需要通过交叉验证对 L1 范数惩罚进行超参数调优。不幸的是，我们不能使用 `LassoCV` 模型类。这是因为它不支持标准化，而且事先对整个数据集进行标准化会污染折叠数据。为了防止这种情况发生，我们将进行如下随机搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fsnm7IplSEzD"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10101)\n",
    "num_tries = 500\n",
    "best_alpha = None\n",
    "best_score = -np.inf\n",
    "for i in range(num_tries):\n",
    "    # 在区间[0.001, 1000]内对alpha进行对数线性搜索\n",
    "    exponent = np.random.uniform(-3, 3)\n",
    "    alpha = np.power(10, exponent)\n",
    "    pipeline = make_pipeline(StandardScaler(), linear_model.Lasso(alpha=alpha))\n",
    "    scores = cross_val_score(pipeline, Xtrain, ytrain, cv=5, scoring='neg_mean_squared_error')\n",
    "    avg_score = np.mean(scores)\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_alpha = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uDTjWOuSEzE"
   },
   "source": [
    "让我们现在比较在特征预处理后各模型的性能。请注意，我们自定义的函数`L0-regression`确实支持特征标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "-1jq76jUSEzE",
    "outputId": "1fdb7dc5-ada1-40e9-d6e2-e30d02cb97b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 标准化特征使其具有0均值和1的样本方差\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtrain)\n",
    "Xtrain_std = scaler.transform(Xtrain)\n",
    "Xtest_std = scaler.transform(Xtest)\n",
    "\n",
    "# 使用所有特征的OLS回归\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(Xtrain_std, ytrain)\n",
    "\n",
    "# 具有交叉验证惩罚项(lambda)的Lasso\n",
    "lasso = linear_model.Lasso(alpha=best_alpha)\n",
    "lasso.fit(Xtrain_std, ytrain)\n",
    "# 通过交叉验证选择最佳特征子集的L0回归\n",
    "intercept, beta = L0_regression(Xtrain, ytrain, standardize=True, seed=10101)\n",
    "\n",
    "# 使用条形图比较它们的性能\n",
    "performance = []\n",
    "performance.append(mse(ytest, lr.predict(Xtest_std)))\n",
    "performance.append(mse(ytest, lasso.predict(Xtest_std)))\n",
    "performance.append(mse(ytest, np.dot(Xtest_std, beta) + intercept))\n",
    "plot_bar_chart(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8xiVKMKSEzE"
   },
   "source": [
    "正如预期的那样，Lasso比OLS表现得更好(尽管差异很小)。这是因为当预算 $s$ 足够大时(或者说当 $\\lambda$ 足够小时)，Lasso可以恢复 $\\beta_{OLS}$ 估计。另一方面，它略逊于L0回归，主要是因为通过收缩 $\\beta$ 我们给估计增加了偏差。此外，观察到L0回归使用最少的特征数量实现了最佳性能。这很方便，因为它导致了一个更容易解释的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqiC7MsBSEzF",
    "outputId": "fb68f4d5-112f-4c77-e3bc-5f97b59030c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS regression kept 13 features.\n",
      "The Lasso kept 12 features.\n",
      "L0-Regression kept 11 features.\n"
     ]
    }
   ],
   "source": [
    "ols_features = np.sum(np.abs(lr.coef_) >= 1e-8)\n",
    "lasso_features = np.sum(np.abs(lasso.coef_) >= 1e-8)\n",
    "l0_features = np.sum(np.abs(beta) >= 1e-8)\n",
    "print(\"OLS regression kept {0} features.\".format(ols_features))\n",
    "print(\"The Lasso kept {0} features.\".format(lasso_features))\n",
    "print(\"L0-Regression kept {0} features.\".format(l0_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk6O3k-PSEzF"
   },
   "source": [
    "### 最终模型\n",
    "\n",
    "前面的分析表明L0回归建议的模型是最佳候选。结果方程如下：\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{medv} = 22.56-1.02\\text{crim}+1.46\\text{zn}+0.49\\text{chas}-1.93\\text{nox}+2.53\\text{rm}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "-3.48\\text{dis}+2.65\\text{rad}-2.22\\text{tax}-1.87\\text{ptratio}+1.00\\text{b}-3.69\\text{lstat}\n",
    "\\end{equation}\n",
    "\n",
    "**注意：** 可以通过`scaler.mean_`和`scaler.var_`分别访问标准化步骤中使用的均值和方差向量。\n",
    "\n",
    "由于我们标准化了数据，截距代表了一个在所有特征上都取平均值的房屋的估计中值(以千美元计)。同样，我们可以解释 $\\beta_1=-1.02$ 为：在其他条件相同的情况下，当人均犯罪率从平均值增加一个标准差时房屋价值的降低量(对其他特征可以做类似解释)。最后，如果分析的主要目的是解释响应变量的变异性，11个特征可能太多了。不过，请记住，人们总是可以将活动特征的数量设置为一个更容易管理的数字以便于解释，尽管可能会以牺牲预测能力为代价。\n",
    "\n",
    "---\n",
    "## 结论\n",
    "\n",
    "我们已经展示了如何使用数学规划来对线性回归问题进行特征选择。事实上，它是Lasso的一个很好的替代方案，因为L0回归具有尺度不变性，并且不会给权重估计增加偏差。此外，这种方法易于指定额外的线性约束(Bertsimas, 2015)，例如：\n",
    "\n",
    "- 在特征之间执行组稀疏性。\n",
    "- 限制成对多重共线性。\n",
    "- 限制全局多重共线性。\n",
    "- 考虑固定集合的非线性变换。\n",
    "\n",
    "然而，对这个结果要谨慎对待，因为\"统计学中没有免费的午餐\"。也就是说，没有一种算法在所有可能的数据集上都优于其他算法。最终，一个优秀的数据科学家在分析数据集时应该考虑多种学习算法。\n",
    "\n",
    "---\n",
    "## 参考文献\n",
    "\n",
    "1. Bertsimas, D., & King, A. (2015). OR forum—An algorithmic approach to linear regression. Operations Research, 64(1), 2-16。\n",
    "2. Bertsimas, D., King, A., & Mazumder, R. (2016). Best subset selection via a modern optimization lens. The annals of statistics, 44(2), 813-852。\n",
    "3. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning. New York: springer。\n",
    "4. The Boston housing dataset (1996, October 10). Retrieved from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHabIFYMSEzF"
   },
   "source": [
    "Copyright © 2020 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
